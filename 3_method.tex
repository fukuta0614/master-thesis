\chapter{提案手法}

\section{概要}
本章では、本研究で提案するシステムについて説明する。
本研究では、識別精度を犠牲にすることなくアノテーションコストを最小化する病理画像解析のための深層能動学習システムを構築する。
高精度を達成するために識別器にConvolutional Neural Networkを採用し、少ないラベル数でも学習を収束させるために
ImageNetで学習済みのpretrained-networkの重みからfinetuneして学習を行う。
一般画像認識のために学習されたモデルでも、医療画像解析への転移学習は幅広いタスクに対して有効であると知られているため、妥当であると考えられる。

また、前章で述べた深層学習と能動学習の組み合わせの問題に対する解決するためのアプローチとして、Query-By-Dropout-Predictionsを提案する。
不確かさを定義しない多層ニューラルネットワークを効率的にパラメータを更新するためのサンプルを見つけるために、予測時にもDropuotを利用するアプローチである。
さらに、医療画像解析において重要であると考えられる様々な変形に対する不変性の担保を考慮し、
各Committeeのprediction時にもランダムなData Augmentationを利用することで、識別に有効なサンプルのみではなく
不変性を確保するために有効であるサンプルをクエリとして選択することを考える。
また、能動学習において一般に問題となるサンプリングバイアスを解決するためにクラスタリング手法を採用し、
その際に用いる特徴量について妥当だと考えられるものを実験から選定した。

以下の節では、それぞれについて詳細を説明する。

\clearpage

\begin{figure}[tbp]
    \label{fig:overview}
     \begin{center}
      \includegraphics[width=120mm]{figures/overview.png}
     \end{center}
    \caption{本研究で提案するシステムの概念図}
\end{figure}

\section{Query by Dropout predictions}
多層ニューラルネットワークによって識別問題を解く際には、最終出力が各ラベルに対応する確率となる確率分布となるように設計して学習を行う。
多層ニューラルネットワークを能動学習に利用する際にはこの確率分布のエントロピーの大きさなどを利用して不確かさを定量評価し、
Uncertainty Samplingによってクエリ選択を行う。
しかし、前章で述べたように、ニューラルネットワーク自体のパラメータに対する不確かさをモデルしているわけではない。
このように不確かさを陽にモデル化しない識別器を利用した能動学習においては、
バージョン空間を近似的に保持することで有効なサンプルを選択するQuery By Committeeを用いる事が多いが、
多層ニューラルネットワークのように非常に計算コストの重いモデルを複数同時に保持し学習を行うことはメモリ、
計算時間等様々な問題で現実的ではないという問題があった。
そこで、本研究では、多くの深層学習のアーキテクチャで正則化の目的で利用されるDropoutによって、
本体のネットワークからサンプリングされた部分ネットワークをCommitteeとみなし、
それらの予測の不一致度を利用して近似的にQuery-By-Committeeを行う手法を提案する（Fig.\ref{fig:query_by_dropout}）。
つまり、本体のネットワーク$\mathcal{M}$から生成された部分ネットワーク$\mathcal{C} = \{\mathcal{M}_{p_1}, \mathcal{M}_{p_2}, \dots, \mathcal{M}_{p_c} \}$を用いて
以下のAverage Kullback Divergenceを計算する。
\begin{eqnarray}
    score(x) =  -  \frac{1}{C} \sum_{c=i}^C KL \, (P_{\theta^{(c)}} || P_C)
\end{eqnarray}
\todo{disagreementだけじゃなくて不確かさも利用する話どこでしようかな}
これらの部分ネットワークがCommitteeとして利用されるためには、それらが訓練データに対してはConsistentであり、
かつ、それぞれの未知データに対する出力には分散を持つ必要がある。
この性質について実験で検証し、Uncertainty Samplingのみを利用する方法と比較する。

\begin{figure}[tbp]
    \label{fig:query_by_dropout}
     \begin{center}
      \includegraphics[width=120mm]{figures/query_by_dropout.png}
     \end{center}
    \caption{Dropoutによってサンプリングされた部分ネットワークによってCommitteeを形成する。}
\end{figure}

\section{推論時でのData Augmentationの利用}
CNNを学習させる際、訓練時に画像に対してData Augmentationを利用することで不変性を獲得させ、結果的に汎化性能を向上させる工夫が用いられる。
医療画像解析では、一般画像認識と比較してモデルが獲得すべき不変性が多く存在する。回転不変性、色相不変性、などがある。
ラベル付きデータが少ない場合には特に有効であると知られており、本研究でも識別器の学習に使用する。
上記でDropoutによって部分ネットワークCommitteeを生成することで不一致度を図る手法を提案したが、
本研究ではそれだけではなく、Data Augmentationを推論時にも利用することで、

\section{提案手法の動作原理}
pre-trained networkを利用する。
基本的にはdropoutはfully connected層で行う
よってそれらは識別境界を大きく変更させるためのサンプルを取得することができる。
Data augmentationを利用することで

\section{バッチ型能動学習への拡張}
能動学習では、クエリ問い合わせを行いラベルデータを拡充するごとに、識別器をfrom scracthから学習させるのが一般的である。
深層学習器を能動学習に利用する場合、一度の再学習に大きな計算コストがかかってしまうため、
各クエリ問い合わせにおいて複数のサンプルにラベルを付与するバッチ型能動学習を採用するのが適当であると考えられる。
一度に投げるクエリ内での情報の重複を避けるために何らかの工夫をする必要があるが、
２章で述べたような劣モジュラ関数を設計するのは深層学習を利用する場合計算コストの観点から難しい。
そこで、本研究ではクラスタリングにより同一のクラスターに属するサンプルは2つ以上選択しないとすることで、情報の重複を避ける。
また、クラスタリングに使用する特徴量の候補として、以下の3つを考慮した。

\subsubsection{hand-crafted feature}
2章で述べたように、病理画像解析にはテクスチャ解析で用いられる技術がしばしば使用される。
ここでは、パターンベースの特徴量で、位置不変性と輝度変化への頑健性を有するLocal Binary Pattern (LBP)を採用する。
実際には、回転不変性を担保させるようにLBPを改良したimproved LBPを利用した。

\subsubsection{CNNの中間特徴量}
Imagenetで学習された特徴量は様々なタスクに有用であるとされており、多数の医療画像解析で利用されている。
本研究ではGoogleNetの中間特徴量512次元を利用した。

\subsubsection{compact bilinear poolingによる特徴量}
近年の深層学習を用いたテクスチャ解析の研究で、Bilinear Poolingによって空間情報をなくした特徴量がしばしば利用される。
これは、CNNの中間特徴量の相関行列を計算し空間方向に平均を取ったものである。
\begin{eqnarray}
G_{ij} = \sum_k{F_{ik} F_{jk}}
\end{eqnarray}
また、一般にCNNの特徴量次元（チャンネル数）は256~512の大きな値であるため、そのまま計算した場合非常に高次元な値となってしまう。
そこで、その近似手法であるCompact Bilinear Pooling\cite{gao2016compact}を本研究ではCNNを用いたテクスチャ特徴量として採用する。

これらを比較するために、それぞれの特徴量を用いて病理画像データセットをK-meansによってクラスタリングを行った際の
各クラスター内のラベルの不純度を平均を計算した。不純度が小さいほどクラスター内でのばらつきが小さく良い特徴量だと言える\todo{ちょいあやしいか}。
データセットは100000枚の病理画像からなり、癌と正常の割合は均等に調整した。
使用したデータセットの詳細は第5章で説明する。
表\ref{table:compare_feat}に示すように、CNNを用いたテクスチャ特徴量であるCompact Bilinear Poolingをクラスタリングに用いるのが妥当であると考えられる。

\begin{table}[h]
  \label{table:compare_feat}
  \caption{比較実験の結果}
  \center
  \begin{tabular}{c|c} \hline
     手法 & Accuracy \\ \hline
    LBP & 0.396 \\
    CNNの中間特徴量 & 0.335  \\ 
    Compact Bilinear Pooling & $\textbf{0.330}$ \\ \hline
  \end{tabular}
\end{table}

\section{アルゴリズムの詳細}

Algorithm.\ref{algo:dal}に本研究で提案するアルゴリズムの詳細を示した。


\begin{algorithm}[h]
    \caption{Deep Active Learning for Pathological Image Analysis}
    \label{algo:dal}
    \begin{algorithmic}
        \STATE \textbf{Input: } 
        unlabeled dataset $\mathcal{U}$,
        clustering size $k$, 
        active sampling size $K$,
    \end{algorithmic}

    \begin{algorithmic}
        \STATE \textbf{Output: } paramters of network $\mathcal{M}$
    \end{algorithmic}
    
    \begin{algorithmic}[1]
        \STATE Initialize pre-trained network $\mathcal{M}_{pretrained}$
        \STATE Perform k-means clustering with texture representation \\
        and devide $\mathcal{U}$ to disjoint clusters $\mathcal{U}_1, \mathcal{U}_2, \dots, \mathcal{U}_k$
        \STATE Initialize labeled dataset $\mathcal{L}$ from each disjoint clusters
        \STATE $\mathcal{M} \leftarrow train (\mathcal{M}_{pretrained}, \mathcal{L})$
        \REPEAT
            \STATE sample committees $\mathcal{C} = \{\mathcal{M}_{p_1}, \mathcal{M}_{p_2}, \dots, \mathcal{M}_{p_c} \}$ from $\mathcal{M}$ using $dropout$ 
            \FOR {$each \; x_i \in \mathcal{U}$}
                \STATE $score (x) \; = disagreement\_score \; (x, \; \mathcal{C}) $
            \ENDFOR
            \STATE $\mathcal{Q} \leftarrow \O$, $\mathcal{D} \leftarrow \O$
            \WHILE{$len(\mathcal{Q}) < K$}
            \STATE $x^{\ast} = \argmax_{x \in \mathcal{U}} score(x)$
            \STATE $idx = cluster(x^{\ast})$
            \IF{$idx \notin D$}
            \STATE $\mathcal{Q} \leftarrow \mathcal{Q} \cup \{x^{\ast}\}, \mathcal{D} \leftarrow \mathcal{D} \cup \{idx\}$

            \ENDIF

            \ENDWHILE
            \STATE Query labels for $\mathcal{Q}$
            \STATE $\mathcal{L} \leftarrow \mathcal{L} \cup \mathcal{Q}$
            \STATE $\mathcal{M} \leftarrow train (\mathcal{M}_{pretrained}, \mathcal{L})$

      \UNTIL{perfomance is satisfactory}
    \end{algorithmic}
  \end{algorithm}
  